{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT0hS9a67BOlarE9gcRUg2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikojim/llms/blob/main/gpt_rag_langchain_faiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sNTcYH5VXhdl",
        "outputId": "db97d9be-bd1f-46da-9045-3fc92c47dbf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain openai faiss-cpu langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kpe3bTDicyDV",
        "outputId": "ab68b754-7e76-4aa4-e73d-1691c8a2ebbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.17-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.59)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.78.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-openai) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-openai) (2.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.59->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.59->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.59->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.59->langchain-openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.17-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from glob import glob\n",
        "from langchain_openai import OpenAIEmbeddings  # Correct package\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain.docstore.document import Document\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Set API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n"
      ],
      "metadata": {
        "id": "GGFr2-BeXpsN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Step 1: Load and Prepare Documents from Directory --------\n",
        "def load_documents_from_directory(directory_path):\n",
        "    documents = []\n",
        "\n",
        "    json_files = glob(os.path.join(directory_path, \"*.json\"))\n",
        "\n",
        "    for file_path in json_files:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            try:\n",
        "                records = json.load(f)\n",
        "                if isinstance(records, dict):\n",
        "                    records = [records]\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {file_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "            for record in records:\n",
        "                incidente = record.get(\"id\", \"\")\n",
        "                creador = record.get(\"owner\", \"\")\n",
        "                asunto = record.get(\"subject\", \"\")\n",
        "                estado = record.get(\"status\", \"\")\n",
        "                creado = record.get(\"created\", \"\")\n",
        "                ultima_modificacion = record.get(\"lastUpdated\", \"\")\n",
        "                transactions = record.get(\"transactions\", [])\n",
        "                transaction_texts = \"\\n\".join(\n",
        "                    f\"[{t.get('fecha')}] {t.get('usuario')}: {t.get('texto', '')}\"\n",
        "                    for t in transactions\n",
        "                )\n",
        "                # Combine all into one document\n",
        "                content = (\n",
        "                    f\"Incidente: {incidente}\\n\"\n",
        "                    f\"Creador: {creador}\\n\"\n",
        "                    f\"Estado: {estado}\\n\"\n",
        "                    f\"Asunto: {asunto}\\n\"\n",
        "                    f\"Creado: {creado}\\n\"\n",
        "                    f\"Última modificación: {ultima_modificacion}\\n\\n\"\n",
        "                    f\"Transacciones:\\n{transaction_texts}\"\n",
        "                )\n",
        "\n",
        "                # add metadata\n",
        "                metadata = {\n",
        "                    \"Incidente\": incidente,\n",
        "                    \"Creador\": creador,\n",
        "                    \"Asunto\": asunto,\n",
        "                    \"Estado\": estado,\n",
        "                    \"Creado\": creado,\n",
        "                }\n",
        "\n",
        "                documents.append(Document(page_content=content, metadata=metadata))\n",
        "\n",
        "    return documents\n"
      ],
      "metadata": {
        "id": "sCHjtQZAX4jU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Step 2: Create FAISS DB with LangChain --------\n",
        "def create_faiss_index(documents):\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "    return vectorstore\n",
        "\n"
      ],
      "metadata": {
        "id": "Q6B2I1CTX98_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Step 3: RAG-style Query Function --------\n",
        "def rag_query(query, vectorstore):\n",
        "    relevant_docs = vectorstore.similarity_search(query, k=3)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "\n",
        "    llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=\"\"\"\"\n",
        "            You are an assistant that responds for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
        "            If you don't know the answer, just say that you don't know.\n",
        "            Answer in bullet points. Make sure your answer is relevant to the question and it is answered from the context only.\n",
        "            Answer in spanish.\n",
        "            \"\"\"),\n",
        "        HumanMessage(content=f\"Context:\\n{context}\\n\\nQuestion: {query}\")\n",
        "    ]\n",
        "\n",
        "    response = llm.invoke(messages)\n",
        "    return response.content\n"
      ],
      "metadata": {
        "id": "8N7tGXsaYAsK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Similarity searcha Faiss Query Function --------\n",
        "def get_similar_documents(query: str, vectorstore: FAISS, k: int = 3):\n",
        "    \"\"\"\n",
        "    Returns the top-k most similar documents from a FAISS vectorstore.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): The search query.\n",
        "    - vectorstore (FAISS): The loaded FAISS vectorstore.\n",
        "    - k (int): Number of top similar documents to return.\n",
        "\n",
        "    Returns:\n",
        "    - List[Document]: The most similar documents.\n",
        "    \"\"\"\n",
        "    return vectorstore.similarity_search(query, k=k)"
      ],
      "metadata": {
        "id": "oAuvxDQvnikI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Filter by metadata --------\n",
        "def filter_documents_by_metadata(vectorstore, filters: dict, k: int = 5):\n",
        "    \"\"\"\n",
        "    Retrieve documents from a LangChain FAISS vectorstore by metadata filters.\n",
        "\n",
        "    Parameters:\n",
        "    - vectorstore: FAISS vectorstore (must be created with metadata)\n",
        "    - filters (dict): e.g., {\"creador\": \"lperna\", \"asunto\": \"Problemas en el mail\"}\n",
        "    - k (int): Number of documents to retrieve (optional)\n",
        "\n",
        "    Returns:\n",
        "    - List[Document]: Filtered documents\n",
        "    \"\"\"\n",
        "    all_docs = vectorstore.similarity_search(\"\", k=1000)  # empty query to get all docs\n",
        "    filtered_docs = []\n",
        "\n",
        "    for doc in all_docs:\n",
        "        if all(doc.metadata.get(key) == value for key, value in filters.items()):\n",
        "            filtered_docs.append(doc)\n",
        "            if len(filtered_docs) >= k:\n",
        "                break\n",
        "\n",
        "    return filtered_docs"
      ],
      "metadata": {
        "id": "Ts5m-97aq2k1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Main Execution --------\n",
        "directory = \"/content/sample_data/json-dataset\"\n",
        "docs = load_documents_from_directory(directory)\n",
        "\n"
      ],
      "metadata": {
        "id": "BOs7rz8bYDPo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV6-mARimIbt",
        "outputId": "5bda6742-48c7-46e1-aa07-991d9c380503"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'Incidente': '16059', 'Creador': 'lkarabogosian', 'Asunto': 'Solicitud 2 PC para equipo seguridad', 'Estado': 'resolved', 'Creado': '2025-01-02 19:09:08'}, page_content='Incidente: 16059\\nCreador: lkarabogosian\\nEstado: resolved\\nAsunto: Solicitud 2 PC para equipo seguridad\\nCreado: 2025-01-02 19:09:08\\nÚltima modificación: 2025-01-14 15:18:00\\n\\nTransacciones:\\n[2025-01-02 19:09:08] gguerrero@tilsor.com.uy: gguerrero@tilsor.com.uy\\n[2025-01-02 19:09:08] gguerrero@tilsor.com.uy: Hola,  Ahora que est n con el cambio de PCs, quer a pedirles si 2 pueden ser  apartadas para ser utilizadas en el futuro por el equipo de seguridad  Lo ideal ser a tener:  - una de 16GB de RAM y la otra de 32GB de RAM - CPU ah  nos arreglamos pero de ser posible lo mejor de lo que les sobre - disco SSD para cada una para el SO - el SO le instalamos Linux nosotros despu s, as  que por eso no se  preocupen  Saludos, Guillermo         \\n[2025-01-03 18:06:16] lperna: Buenas Guille,  No creo que tenga ninguna mother que soporte 32gb de ram. Tal vez alguna que soporte 16gb de ram pero no mas de DDR3, por otro lado los equipos que est n sobrando que pueden estar en la vuelta tienen una CPU que son i3 o i5 generaci n 3 o 4 bastante vieja. Pero tengo que ver. Depende la demanda que se le de te puede ir mejor o peor. Pero como mencione una mother q soporte 32gb ya te digo q es bastante dif cil q tenga. Veo lo que va quedando y vemos q se puede armar.  Saludos Leo.P   \\n[2025-01-09 13:57:02] lkarabogosian: Buen d a, con la desafectaci n de algunos equipos por el reemplazo de nuevos, pudimos encontrar una motherboard que contenga 4 slots y soporte los 32GB (no m s). Prepararemos los equipos, realizaremos los test de las memorias y avisaremos cuando est  todo listo.  Saludos    \\n[2025-01-13 12:14:09] gguerrero@tilsor.com.uy: Genial, muchas gracias!  Saludos, Guillermo  El 09/01/2025 a las 10:57, lkarabogosian via RT escribi : > Buen d a, con la desafectaci n de algunos equipos por el reemplazo de nuevos, pudimos encontrar una motherboard que contenga 4 slots y soporte los 32GB (no m s). > Prepararemos los equipos, realizaremos los test de las memorias y avisaremos cuando est  todo listo. > > Saludos       \\n[2025-01-14 15:17:59] lkarabogosian: Se ha entregado a Guillermo Guerrero los equipos PC-202 y PC-203, junto con un teclado y un mouse, ambos usb con cable. Como la instalaci n del sistema operativo la realizar  Seguridad, no tenemos los nombres de los equipos. Tampoco tienen IPs asignadas. Comentado con Guillermo, nos solicitar n la asignaci n de las IPs cuando se defina en qu  red van a estar estos equipos. Cierro ticket.     ')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------Load Faiss DB\n",
        "if not docs:\n",
        "    print(\"No documents found.\")\n",
        "else:\n",
        "    vectorstore = create_faiss_index(docs)"
      ],
      "metadata": {
        "id": "QCPORmwalo0v"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------Test document search by context\n",
        "query = \"15440\"\n",
        "similar_docs = get_similar_documents(query, vectorstore, k=3)\n",
        "\n",
        "for i, doc in enumerate(similar_docs, 1):\n",
        "    print(f\"--- Document {i} ---\\n{doc.page_content}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-aB3dVfltCk",
        "outputId": "7c3fc382-cda5-4156-a7f9-473db82439c0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Document 1 ---\n",
            "Incidente: 16036\n",
            "Creador: lperna\n",
            "Estado: resolved\n",
            "Asunto: Mouse pad\n",
            "Creado: 2024-12-31 12:02:28\n",
            "Última modificación: 2025-01-03 17:25:53\n",
            "\n",
            "Transacciones:\n",
            "[2024-12-31 12:02:28] asanchez@tilsor.com.uy: asanchez@tilsor.com.uy\n",
            "[2024-12-31 12:02:28] asanchez@tilsor.com.uy: Buen d a:  Estar a necesitando un mouse pad o similar.  Saludos. Agustin S.     \n",
            "\n",
            "--- Document 2 ---\n",
            "Incidente: 15101\n",
            "Creador: lkarabogosian\n",
            "Estado: resolved\n",
            "Asunto: Testeo Nueva app Abitab\n",
            "Creado: 2024-10-28 19:50:42\n",
            "Última modificación: 2025-01-13 14:00:40\n",
            "\n",
            "Transacciones:\n",
            "[2024-10-28 19:50:42] rlopez: rlopez\n",
            "[2024-10-28 19:50:42] rlopez: Buenas tardes, c mo hablamos con Fernanda,  en los pr ximos d as  estaremos liberando un aplicativo nuevo a Abitab, y previamente  necesitamos probar y validarlo su uso con los celulares , especialmente  por los navegadores espec ficos: Samsung, Safari .  Lo que hablamos con Fernanda hoy es que usar amos el acceso por internet  que se hizo para:  https://sirfe-rs.tilsor.com.uy/aif-rs/ws/public/ws_efactura_intercambio?wsdl  pero apuntando a un servidor JBoss nuevo (otra IP) en la red de desarrollo.  En cuanto tengamos la virtual desplegada , anexamos al ticket  la URL y  la IP interna.  Ser a por 2 o 3 d as para hacer un testeo interno r pido y luego se  apaga el acceso externo, quedando solo los ambientes en la red de  desarrollo.  Gracias              \n",
            "[2024-10-31 20:04:49] rlopez: Buenas tardes, ya tenemos el JBoss desplegado en la red de desarrollo,   se accede internamente en:  https://abitab-web.tilsor.com.uy:8443/pkiKeyGenerator/  Solicitamos configurar VH 'pki.tilsor.com.uy' para internet:  https://pki.tilsor.com.uy/pkiKeyGenerator/  En el mismo WAF donde actualmente se publica sirfe-rs.  Gracias   On 28/10/2024 16:50, Soporte Interno de Tilsor via RT wrote: > Esta es una respuesta autom tica por la creaci n del ticket #15101 con  > el asunto: > > *Testeo Nueva app Abitab* > > Si desea enviarnos un e-mail relacionado con este tema, puede  > responder a este mismo e-mail o crear uno nuevo haciendo click aqu   > <mailto:solicitudes_soporte_interno@tilsor.com.uy?subject=[Solicitudes  > #15101] Testeo Nueva app Abitab> > > Muchas Gracias, > Soporte Interno > Tilsor S.A. >    \n",
            "[2024-10-31 21:20:27] fmolina: Hola,  Se realiza pedido de configuraci n del WAF en ticket Mantis 17914  Saludos \n",
            "[2025-01-03 15:15:31] fmolina: Hola Rodrigo,   Esto se sigue precisando?  Saludos,  Fernanda \n",
            "[2025-01-13 12:42:59] rlopez: Buen d a, c mo andas Fer?   Si, como hab amos planteado un acceso  temporal, se puede quitar el acceso externo.  Gracias.   On 03/01/2025 12:15, fmolina via RT wrote: > Hola Rodrigo, > >  Esto se sigue precisando? > > Saludos, > > Fernanda        \n",
            "[2025-01-13 14:00:39] lkarabogosian: Se quita la linea en el DNS: pki IN A 190.64.148.230  Se comprob  que desde afuera no apunte m s a la IP 190.64.148.230.  Se abri  ticket en Mantis '18218: Configuraci n WAF-Test: Retirar el acceso externo al servidor pki.tilsor.com.uy (Ticket: 17914)', para que borren la configuraci n del WAF.  Cierro ticket.     \n",
            "\n",
            "--- Document 3 ---\n",
            "Incidente: 15560\n",
            "Creador: lperna\n",
            "Estado: resolved\n",
            "Asunto: Maquina de sala de reuniones 402\n",
            "Creado: 2024-11-27 19:13:42\n",
            "Última modificación: 2025-01-03 14:14:41\n",
            "\n",
            "Transacciones:\n",
            "[2024-11-27 19:13:42] amartin: amartin\n",
            "[2024-11-27 19:13:42] amartin: Hola a todos. La maquina de sala de reuniones 402 fue formateada o reinstalado windows? Justo hoy teniamos reuni n con un clientey cuando llego, Rodrigo Martinez hab ado iniciado sesi n y por ejemplo no tenia ni el zoom instalado. Prob  con mi usuario (habr  entrado a esa maquina hace tres semanas) y me da tambi n el mensaje de bienvenida y espere a que se termine de configurar. Al final tuvimos que utilizar el notebook de Rodrigo.  Podr an revisarla y dejarla utilizable?   Gracias!  Ale   --  Alejandra Mart n  TILSOR SA  Consultor  29039313 Int. 146          \n",
            "[2024-11-27 20:15:42] esoria: Alejandra, c mo est s?                          los perfiles de usuario en las PCs de las salas de reuniones (todas) se eliminan peri dicamente.  Esto es debido a que cada usuario consume un determinado espacio de disco y en determinado momento el PC se queda sin espacio, quedando no utilizable.  Una vez que el perfil es eliminado, en el siguiente inicio de sesi n se vuelve a crear autom ticamente. En el caso del Zoom, el instalador es por perfil, por lo pueden utilizarlo via web o bien, volver a instalarlo.  Saludos, Eduardo.-     \n",
            "[2024-11-27 20:19:52] amartin: Dale perfecto. Voy a ver si instalo en mi perfil en estos d as, as  ya cuando tengamos otra reuni n lo utilizo.  Gracias! Ale  ----- Mensaje original ----- De: 'esoria via RT' <rt@tilsor.com.uy> Para: 'Alejandra Mart n' <amartin@tilsor.com.uy> Enviados: Mi rcoles, 27 de Noviembre 2024 17:15:42 Asunto: [Solicitudes #15560] Maquina de sala de reuniones 402  Alejandra, c mo est s?                          los perfiles de usuario en las PCs de las salas de reuniones (todas) se eliminan peri dicamente.  Esto es debido a que cada usuario consume un determinado espacio de disco y en determinado momento el PC se queda sin espacio, quedando no utilizable.  Una vez que el perfil es eliminado, en el siguiente inicio de sesi n se vuelve a crear autom ticamente. En el caso del Zoom, el instalador es por perfil, por lo pueden utilizarlo via web o bien, volver a instalarlo.  Saludos, Eduardo.-            \n",
            "[2024-11-27 20:45:38] fmolina: Hola Eduardo,  Habiamos hablado de adelantar la compra de ese pc, veamos de hacerlo lo  antes posible y avisemos a Everyone del cambio, para que sepan que deben  configrar su ambiente antes de una reuni n.  Saludos,  Fernanda  El 27/11/2024 a las 17:15, esoria via RT escribi : > <URL: https://rt.tilsor.com.uy/Ticket/Display.html?id=15560 > > > Alejandra, c mo est s? > >                          los perfiles de usuario en las PCs de las salas de reuniones (todas) se eliminan peri dicamente. > > Esto es debido a que cada usuario consume un determinado espacio de disco y en determinado momento el PC se queda sin espacio, quedando no utilizable. > > Una vez que el perfil es eliminado, en el siguiente inicio de sesi n se vuelve a crear autom ticamente. > En el caso del Zoom, el instalador es por perfil, por lo pueden utilizarlo via web o bien, volver a instalarlo. > > Saludos, > Eduardo.-         \n",
            "[2024-11-27 20:58:10] esoria: Alejandra,            la creaci n del perfil no deber a tomar m s de un par de minutos, aunque igualmente entiendo que cuando el tiempo apremia para una reuni n, un minuto m s cuenta.  De todas formas si te llegara a demorar m s de eso, lo revisamos igualmente.  Saludos, Eduardo.-      \n",
            "[2024-12-17 12:02:31] lperna: Se esta preparando el equipo de la sala 401 y 402 para sus cambios.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------Test document search by metadata\n",
        "filters = {'Incidente': '16059'}\n",
        "filtered_docs = filter_documents_by_metadata(vectorstore, filters, k=3)\n",
        "\n",
        "for doc in filtered_docs:\n",
        "    print(\"Metadata:\", doc.metadata)\n",
        "    print(\"Content:\\n\", doc.page_content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFn99XrspkNf",
        "outputId": "d7351f7d-3c72-4736-ec9e-db483526c8ec"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata: {'Incidente': '16059', 'Creador': 'lkarabogosian', 'Asunto': 'Solicitud 2 PC para equipo seguridad', 'Estado': 'resolved', 'Creado': '2025-01-02 19:09:08'}\n",
            "Content:\n",
            " Incidente: 16059\n",
            "Creador: lkarabogosian\n",
            "Estado: resolved\n",
            "Asunto: Solicitud 2 PC para equipo seguridad\n",
            "Creado: 2025-01-02 19:09:08\n",
            "Última modificación: 2025-01-14 15:18:00\n",
            "\n",
            "Transacciones:\n",
            "[2025-01-02 19:09:08] gguerrero@tilsor.com.uy: gguerrero@tilsor.com.uy\n",
            "[2025-01-02 19:09:08] gguerrero@tilsor.com.uy: Hola,  Ahora que est n con el cambio de PCs, quer a pedirles si 2 pueden ser  apartadas para ser utilizadas en el futuro por el equipo de seguridad  Lo ideal ser a tener:  - una de 16GB de RAM y la otra de 32GB de RAM - CPU ah  nos arreglamos pero de ser posible lo mejor de lo que les sobre - disco SSD para cada una para el SO - el SO le instalamos Linux nosotros despu s, as  que por eso no se  preocupen  Saludos, Guillermo         \n",
            "[2025-01-03 18:06:16] lperna: Buenas Guille,  No creo que tenga ninguna mother que soporte 32gb de ram. Tal vez alguna que soporte 16gb de ram pero no mas de DDR3, por otro lado los equipos que est n sobrando que pueden estar en la vuelta tienen una CPU que son i3 o i5 generaci n 3 o 4 bastante vieja. Pero tengo que ver. Depende la demanda que se le de te puede ir mejor o peor. Pero como mencione una mother q soporte 32gb ya te digo q es bastante dif cil q tenga. Veo lo que va quedando y vemos q se puede armar.  Saludos Leo.P   \n",
            "[2025-01-09 13:57:02] lkarabogosian: Buen d a, con la desafectaci n de algunos equipos por el reemplazo de nuevos, pudimos encontrar una motherboard que contenga 4 slots y soporte los 32GB (no m s). Prepararemos los equipos, realizaremos los test de las memorias y avisaremos cuando est  todo listo.  Saludos    \n",
            "[2025-01-13 12:14:09] gguerrero@tilsor.com.uy: Genial, muchas gracias!  Saludos, Guillermo  El 09/01/2025 a las 10:57, lkarabogosian via RT escribi : > Buen d a, con la desafectaci n de algunos equipos por el reemplazo de nuevos, pudimos encontrar una motherboard que contenga 4 slots y soporte los 32GB (no m s). > Prepararemos los equipos, realizaremos los test de las memorias y avisaremos cuando est  todo listo. > > Saludos       \n",
            "[2025-01-14 15:17:59] lkarabogosian: Se ha entregado a Guillermo Guerrero los equipos PC-202 y PC-203, junto con un teclado y un mouse, ambos usb con cable. Como la instalaci n del sistema operativo la realizar  Seguridad, no tenemos los nombres de los equipos. Tampoco tienen IPs asignadas. Comentado con Guillermo, nos solicitar n la asignaci n de las IPs cuando se defina en qu  red van a estar estos equipos. Cierro ticket.     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"problemas WAF\"\n",
        "answer = rag_query(query, vectorstore)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNU6hx_uYH9y",
        "outputId": "a61615a2-a8a0-4c0a-9cdb-8f3c5884f3f5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Según el contexto proporcionado, durante el testeo de la nueva aplicación de Abitab, se solicitó la configuración del WAF (Firewall de Aplicaciones Web) en el ticket Mantis 17914 (Incidente 15101). \n",
            "- Este WAF fue configurado para permitir el acceso a ciertos recursos internos, específicamente la URL https://pki.tilsor.com.uy/pkiKeyGenerator/.\n",
            "- Posteriormente, una vez completada la fase de prueba, el acceso externo a estos recursos se eliminó. Para esta acción, se creó un nuevo ticket Mantis (18218) solicitando la eliminación de la configuración del WAF que permitía el acceso externo al servidor pki.tilsor.com.uy. No se menciona ningún problema relacionado con el WAF en el contexto proporcionado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dRsEx5qDcbW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}